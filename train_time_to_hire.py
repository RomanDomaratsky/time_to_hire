# train_time_to_hire.py

import os
import ast
from collections import Counter
from datetime import datetime

import joblib
import numpy as np
import pandas as pd
import psycopg2
from dotenv import load_dotenv
from scipy.sparse import hstack, csr_matrix
from sklearn.feature_extraction.text import TfidfVectorizer
from xgboost import XGBRegressor

SOFT_SKILLS = {
    "–∫–æ–º—É–Ω—ñ–∫–∞–±–µ–ª—å–Ω—ñ—Å—Ç—å", "—Å—Ç—Ä–µ—Å–æ—Å—Ç—ñ–π–∫—ñ—Å—Ç—å", "–≤—ñ–¥–ø–æ–≤—ñ–¥–∞–ª—å–Ω—ñ—Å—Ç—å", "–∞–∫—Ç–∏–≤–Ω—ñ—Å—Ç—å",
    "–ø—É–Ω–∫—Ç—É–∞–ª—å–Ω—ñ—Å—Ç—å", "–¥–∏—Å—Ü–∏–ø–ª—ñ–Ω–æ–≤–∞–Ω—ñ—Å—Ç—å", "—Å—Ç–∞–±—ñ–ª—å–Ω—ñ—Å—Ç—å", "–æ—Ä–≥–∞–Ω—ñ–∑–æ–≤–∞–Ω—ñ—Å—Ç—å",
    "—É–≤–∞–∂–Ω—ñ—Å—Ç—å", "–±–∞–∂–∞–Ω–Ω—è –≤—á–∏—Ç–∏—Å—è —ñ —Ä–æ–∑–≤–∏–≤–∞—Ç–∏—Å—è", "–±–∞–∂–∞–Ω–Ω—è –≤—á–∏—Ç–∏—Å—è",
    "–±–∞–∂–∞–Ω–Ω—è —Ä–æ–∑–≤–∏–≤–∞—Ç–∏—Å—è", "–∫—Ä–µ–∞—Ç–∏–≤–Ω—ñ—Å—Ç—å", "—É–º—ñ–Ω–Ω—è –ø—Ä–∞—Ü—é–≤–∞—Ç–∏ –≤ –∫–æ–º–∞–Ω–¥—ñ",
    "—Ä–æ–±–æ—Ç–∞ –≤ –∫–æ–º–∞–Ω–¥—ñ", "–ª—ñ–¥–µ—Ä—Å—å–∫—ñ —è–∫–æ—Å—Ç—ñ", "–º–æ—Ç–∏–≤–∞—Ü—ñ—è", "—ñ–Ω—ñ—Ü—ñ–∞—Ç–∏–≤–Ω—ñ—Å—Ç—å",
    "—Å–∞–º–æ–æ—Ä–≥–∞–Ω—ñ–∑–∞—Ü—ñ—è", "–Ω–∞–ø–æ–ª–µ–≥–ª–∏–≤—ñ—Å—Ç—å", "—à–≤–∏–¥–∫–µ –Ω–∞–≤—á–∞–Ω–Ω—è", "–∫–æ–º–∞–Ω–¥–Ω–∞ —Ä–æ–±–æ—Ç–∞",
    "–ø—Ä–∞—Ü—å–æ–≤–∏—Ç—ñ—Å—Ç—å", "–¥–æ–±—Ä–æ–∑–∏—á–ª–∏–≤—ñ—Å—Ç—å"
}


def get_connection():
    load_dotenv()
    return psycopg2.connect(
        host=os.getenv("DB_HOST"),
        database=os.getenv("DB_NAME"),
        user=os.getenv("DB_USER"),
        password=os.getenv("DB_PASSWORD"),
        port=os.getenv("DB_PORT"),
    )


def parse_skill_list(value):
    """–£–Ω—ñ–≤–µ—Ä—Å–∞–ª—å–Ω–∏–π –ø–∞—Ä—Å–µ—Ä skills –¥–ª—è —Ñ–æ—Ä–º–∞—Ç—ñ–≤:
    - {a,b,c}
    - ['a','b']
    - "[\"a\", \"b\"]"
    - "a, b, c"
    - –æ–¥–∏–Ω skill —è–∫ —Å—Ç—Ä–æ–∫–∞
    """
    if value is None:
        return []

    # –≤–∂–µ Python list
    if isinstance(value, list):
        return [str(x).strip() for x in value]

    if isinstance(value, str):
        text = value.strip()

        # —Ä—è–¥–æ–∫, —Å—Ö–æ–∂–∏–π –Ω–∞ —Å–ø–∏—Å–æ–∫
        if (text.startswith("[") and text.endswith("]")):
            try:
                parsed = ast.literal_eval(text)
                if isinstance(parsed, list):
                    return [str(x).strip() for x in parsed]
            except Exception:
                pass

        # PostgreSQL –º–∞—Å–∏–≤ {a,b,c}
        if text.startswith("{") and text.endswith("}"):
            inner = text[1:-1]
            return [s.strip() for s in inner.split(",") if s.strip()]

        # –ø—Ä–æ—Å—Ç–æ "a, b, c"
        if "," in text:
            return [s.strip() for s in text.split(",") if s.strip()]

        # fallback ‚Äî –æ–¥–∏–Ω skill
        return [text]

    # —ñ–Ω—à—ñ —Ç–∏–ø–∏
    return [str(value).strip()]


def clean_skill(skill: str):
    if not skill:
        return None
    s = skill.strip().lower()
    if len(s) < 2:
        return None
    if s in SOFT_SKILLS:
        return None
    return s


def clean_skill_list(skills):
    cleaned = []
    for s in skills:
        cs = clean_skill(s)
        if cs:
            cleaned.append(cs)
    return cleaned


def load_training_data():
    conn = get_connection()
    df = pd.read_sql("""
        SELECT job_id, title, description, skills,
               salary_min, salary_max, salary_average,
               location, category, company,
               posted_date, time_to_hire
        FROM jobs
        WHERE time_to_hire IS NOT NULL
          AND time_to_hire > 0
    """, conn)
    conn.close()
    return df


def build_top_skills(train_df, top_n=300):
    all_skills = []
    for raw in train_df["skills"]:
        parsed = parse_skill_list(raw)
        cleaned = clean_skill_list(parsed)
        all_skills.extend(cleaned)
    counter = Counter(all_skills)
    return [sk for sk, _ in counter.most_common(top_n)]


def one_hot_skills(df, top_skills):
    rows = []
    for raw in df["skills"]:
        parsed = parse_skill_list(raw)
        cleaned = clean_skill_list(parsed)
        sset = set(cleaned)
        rows.append([1 if sk in sset else 0 for sk in top_skills])
    return csr_matrix(np.array(rows))


def add_numeric_features(df):
    out = pd.DataFrame(index=df.index)

    out["salary_min"] = df["salary_min"].fillna(0).astype(float)
    out["salary_max"] = df["salary_max"].fillna(0).astype(float)
    out["salary_avg"] = df["salary_average"].fillna(0).astype(float)

    today = datetime.today().date()
    posted = pd.to_datetime(df["posted_date"], errors="coerce").dt.date

    out["age_days"] = pd.Series([(today - d).days if d else 0 for d in posted], index=df.index)
    out["desc_len"] = df["description"].fillna("").apply(lambda x: len(str(x)))
    out["skills_count"] = df["skills"].apply(
        lambda x: len(clean_skill_list(parse_skill_list(x)))
    )

    return csr_matrix(out.values)


def build_text_vectorizer(train_df):
    texts = (train_df["title"].fillna("") + " " + train_df["description"].fillna(""))
    vectorizer = TfidfVectorizer(max_features=5000, ngram_range=(1, 2), min_df=5)
    X_text = vectorizer.fit_transform(texts)
    return vectorizer, X_text


def main():
    os.makedirs("models", exist_ok=True)

    print("üì• Loading training data...")
    train_df = load_training_data()
    if train_df.empty:
        print("‚ùå No training data with time_to_hire")
        return

    print("üß† Building top skills...")
    top_skills = build_top_skills(train_df, top_n=300)

    print("üì¶ Skills one-hot...")
    X_sk = one_hot_skills(train_df, top_skills)

    print("‚úçÔ∏è Text TF-IDF...")
    vectorizer, X_text = build_text_vectorizer(train_df)

    print("üìä Numeric features...")
    X_num = add_numeric_features(train_df)

    print("üîó Combine features...")
    X_train = hstack([X_text, X_sk, X_num])
    y_train = train_df["time_to_hire"].astype(float).values

    print("üöÄ Train XGBoost...")
    model = XGBRegressor(
        n_estimators=400,
        learning_rate=0.05,
        max_depth=8,
        subsample=0.8,
        colsample_bytree=0.8,
        tree_method="hist",
        objective="reg:squarederror",
    )
    model.fit(X_train, y_train)

    print("üíæ Saving artifacts...")
    joblib.dump(model, "models/time_to_hire_xgb.pkl")
    joblib.dump(vectorizer, "models/time_to_hire_tfidf.pkl")
    joblib.dump(top_skills, "models/time_to_hire_top_skills.pkl")

    print("‚úÖ Done training.")


if __name__ == "__main__":
    main()
